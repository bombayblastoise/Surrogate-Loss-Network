{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f585b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaspreet.brar/ml-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from models import Decoder, Embedder, StrongDecoder\n",
    "from train2 import initialize_embedder, train_surrogate, train_xgb, improve_embedder, freeze\n",
    "from utils import standardize, load_data_custom, get_z_features\n",
    "from analysis import final_embedding_analysis, representation_report, plot_embedding, plot_reconstruction\n",
    "from config import Z_DIM, D_HIDDEN, DEVICE\n",
    "\n",
    "NUM_LOOPS = 8\n",
    "EPOCHS_SURROGATE = 8\n",
    "EPOCHS_AE = 5\n",
    "EPOCHS_IMPROVE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d7c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data/tejas.csv\n",
      " Teacher (XGBoost) Test AUC: 0.7485\n",
      "\n",
      "==================================================\n",
      "ðŸ”„ STARTING TRAINING LOOP (8 Cycles)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "fpath = 'data/tejas.csv'\n",
    "print(f\"Loading data from {fpath}\")\n",
    "raw_X, raw_y = load_data_custom(fpath, 'TARGET')\n",
    "raw_X_train, raw_X_test, y_train, y_test = train_test_split(raw_X, raw_y, random_state=42, test_size=0.2, shuffle=True, stratify=raw_y)\n",
    "std_X_train = standardize(raw_X_train)\n",
    "std_X_test = standardize(raw_X_test, raw_X_train)\n",
    "X_train_np = std_X_train.values\n",
    "X_test_np = std_X_test.values\n",
    "input_dim = X_train_np.shape[1]\n",
    "# train xgb on raw X\n",
    "xgb_teacher = train_xgb(X_train_np, y_train, X_test_np, y_test)\n",
    "dtest = xgb.DMatrix(X_test_np, nthread=8)\n",
    "teacher_preds = xgb_teacher.predict(dtest)\n",
    "teacher_auc = roc_auc_score(y_test, teacher_preds)\n",
    "print(f\" Teacher (XGBoost) Test AUC: {teacher_auc:.4f}\")\n",
    "# initialize models\n",
    "embedder = initialize_embedder(X_train_np, input_dim)\n",
    "ae_embedder = initialize_embedder(X_train_np, input_dim)\n",
    "Z_ae_test = get_z_features(ae_embedder, X_test_np)\n",
    "# we make this to ensure embedder doesnt give garbage\n",
    "decoder = Decoder(Z_DIM, D_HIDDEN, input_dim).to(DEVICE)\n",
    "# training\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"ðŸ”„ STARTING TRAINING LOOP ({NUM_LOOPS} Cycles)\")\n",
    "print(\"=\"*50)\n",
    "surrogate = None\n",
    "Z_prev_train = X_train_np\n",
    "Z_prev_test = X_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8aeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cycle 1 / 8 ---\n",
      "     Training XGBoost on 185 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 1\n",
      "============================================================\n",
      "Teacher AUC          : 0.7488\n",
      "Teacher MSE          : 0.2003\n",
      "Student AUC          : 0.7296\n",
      "Student MSE          : 0.2027\n",
      "Î” MSE (Studentâˆ’Teacher): +0.0024\n",
      "Z Linear Probe AUC   : 0.7080\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 0.6709\n",
      "============================================================\n",
      "\n",
      "--- Cycle 2 / 8 ---\n",
      "     Training XGBoost on 128 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 2\n",
      "============================================================\n",
      "Teacher AUC          : 0.7421\n",
      "Teacher MSE          : 0.2023\n",
      "Student AUC          : 0.7404\n",
      "Student MSE          : 0.2090\n",
      "Î” MSE (Studentâˆ’Teacher): +0.0067\n",
      "Z Linear Probe AUC   : 0.7408\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.0890\n",
      "============================================================\n",
      "\n",
      "--- Cycle 3 / 8 ---\n",
      "     Training XGBoost on 128 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 3\n",
      "============================================================\n",
      "Teacher AUC          : 0.7452\n",
      "Teacher MSE          : 0.2016\n",
      "Student AUC          : 0.7419\n",
      "Student MSE          : 0.2023\n",
      "Î” MSE (Studentâˆ’Teacher): +0.0007\n",
      "Z Linear Probe AUC   : 0.7434\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.1153\n",
      "============================================================\n",
      "\n",
      "--- Cycle 4 / 8 ---\n",
      "     Training XGBoost on 64 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 4\n",
      "============================================================\n",
      "Teacher AUC          : 0.7456\n",
      "Teacher MSE          : 0.2021\n",
      "Student AUC          : 0.7422\n",
      "Student MSE          : 0.1996\n",
      "Î” MSE (Studentâˆ’Teacher): -0.0025\n",
      "Z Linear Probe AUC   : 0.7441\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.0990\n",
      "============================================================\n",
      "\n",
      "--- Cycle 5 / 8 ---\n",
      "     Training XGBoost on 64 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 5\n",
      "============================================================\n",
      "Teacher AUC          : 0.7449\n",
      "Teacher MSE          : 0.2023\n",
      "Student AUC          : 0.7415\n",
      "Student MSE          : 0.2020\n",
      "Î” MSE (Studentâˆ’Teacher): -0.0003\n",
      "Z Linear Probe AUC   : 0.7443\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.0798\n",
      "============================================================\n",
      "\n",
      "--- Cycle 6 / 8 ---\n",
      "     Training XGBoost on 64 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 6\n",
      "============================================================\n",
      "Teacher AUC          : 0.7445\n",
      "Teacher MSE          : 0.2024\n",
      "Student AUC          : 0.7419\n",
      "Student MSE          : 0.2057\n",
      "Î” MSE (Studentâˆ’Teacher): +0.0032\n",
      "Z Linear Probe AUC   : 0.7431\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.0740\n",
      "============================================================\n",
      "\n",
      "--- Cycle 7 / 8 ---\n",
      "     Training XGBoost on 64 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 7\n",
      "============================================================\n",
      "Teacher AUC          : 0.7457\n",
      "Teacher MSE          : 0.2020\n",
      "Student AUC          : 0.7435\n",
      "Student MSE          : 0.1949\n",
      "Î” MSE (Studentâˆ’Teacher): -0.0071\n",
      "Z Linear Probe AUC   : 0.7438\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.0950\n",
      "============================================================\n",
      "\n",
      "--- Cycle 8 / 8 ---\n",
      "     Training XGBoost on 64 features...\n",
      "\n",
      "ðŸ“Š REPRESENTATION REPORT â€” Cycle 8\n",
      "============================================================\n",
      "Teacher AUC          : 0.7445\n",
      "Teacher MSE          : 0.2026\n",
      "Student AUC          : 0.7421\n",
      "Student MSE          : 0.1998\n",
      "Î” MSE (Studentâˆ’Teacher): -0.0028\n",
      "Z Linear Probe AUC   : 0.7434\n",
      "Z Drift              : 0.000000\n",
      "Centroid Distance    : 1.0897\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_LOOPS):\n",
    "    print(f\"\\n--- Cycle {i+1} / {NUM_LOOPS} ---\")\n",
    "    if surrogate is not None:\n",
    "        freeze(surrogate)\n",
    "    # 1. Current embeddings\n",
    "    Z_curr_train = get_z_features(embedder, X_train_np)\n",
    "    Z_curr_test  = get_z_features(embedder, X_test_np)\n",
    "    # 2. Teacher input = [Z_{k-1} | Z_k]\n",
    "    if i < 3:\n",
    "      X_train_xgb = np.hstack([Z_prev_train, Z_curr_train])\n",
    "      X_test_xgb  = np.hstack([Z_prev_test,  Z_curr_test])\n",
    "    else :\n",
    "      X_train_xgb = Z_curr_train\n",
    "      X_test_xgb  = Z_curr_test\n",
    "    # 3. TRAIN XGBOOST (On Augmented Data)al\n",
    "    print(f\"     Training XGBoost on {X_train_xgb.shape[1]} features...\")\n",
    "    xgb_teacher = train_xgb(X_train_xgb, y_train, X_test_xgb, y_test)\n",
    "    dtest = xgb.DMatrix(X_test_xgb, nthread=8)\n",
    "    xgb_auc = roc_auc_score(y_test, xgb_teacher.predict(dtest))\n",
    "    # print(f\"     XGBoost AUC: {xgb_auc:.4f}\")\n",
    "    # 4. Teacher labels (FULL VIEW)\n",
    "    teacher_labels = xgb_teacher.predict(xgb.DMatrix(X_train_xgb))\n",
    "    # 5. TRAIN SURROGATE\n",
    "    # Input: Z_{k} | Target: New XGB Labels\n",
    "    surrogate = train_surrogate(Z_curr_train, teacher_labels)\n",
    "    # 6. IMPROVE EMBEDDER\n",
    "    # Input: Raw Data | Target: New XGB Labels\n",
    "    embedder = improve_embedder(X_train_np, y_train, embedder, surrogate)\n",
    "    # 7. Store Zk for next round\n",
    "    Z_prev_train = Z_curr_train.copy()\n",
    "    Z_prev_test  = Z_curr_test.copy()\n",
    "    # 8. stats\n",
    "    representation_report(\n",
    "        cycle=i+1,\n",
    "        embedder=embedder,\n",
    "        surrogate=surrogate,\n",
    "        xgb_teacher=xgb_teacher,\n",
    "        Z_prev_train=Z_prev_train,\n",
    "        Z_curr_train=Z_curr_train,\n",
    "        Z_curr_test=Z_curr_test,\n",
    "        X_test_xgb=X_test_xgb,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        device=DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc266863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            TRAINING PROGRESS REPORT                            \n",
      "================================================================================\n",
      "\n",
      "ðŸ” FINAL EMBEDDING ANALYSIS\n",
      "============================================================\n",
      "ðŸ“ˆ Z Linear Probe AUC: 0.7427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaspreet.brar/ml-env/lib/python3.11/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Centroid distance (fraud vs legit): 1.0596\n",
      "ðŸ” Reconstruction MSE: 3.1369\n",
      "ðŸ”‘ Most important Z dims (linear probe): [10, 9, 60, 59, 61, 6, 5, 31, 29, 36]\n",
      "============================================================\n",
      "âœ” Interpretation guide:\n",
      "- Clear class separation â†’ Z learned structure\n",
      "- High probe AUC â†’ Z encodes truth\n",
      "- Low recon error â†’ Z preserved info\n",
      "- Tight clusters â†’ stable embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{'TRAINING PROGRESS REPORT':^80}\")\n",
    "print(\"=\"*80)\n",
    "# --- 6. ANALYSIS ---\n",
    "final_embedding_analysis(\n",
    "embedder=embedder,\n",
    "decoder=decoder,\n",
    "X_train=X_train_np,\n",
    "X_test=X_test_np,\n",
    "y_train=y_train,\n",
    "y_test=y_test,\n",
    "device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420799a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og_vec :  [ 1.15336883e+00 -3.24585676e-01  1.38717163e+00  1.39386368e+00\n",
      "  6.64271057e-01  8.11107457e-01 -4.38414514e-02  4.24492717e-01\n",
      "  2.45743483e-01  4.05436456e-01 -2.37868142e+00  9.15270090e-01\n",
      " -1.68622971e+00 -4.04029608e-01 -3.04918438e-01 -7.74242342e-01\n",
      "  5.78408539e-01 -4.51414317e-01  5.99675059e-01 -9.33419228e-01\n",
      "  5.82867742e-01  2.01031705e-03  4.67698932e-01 -4.99500692e-01\n",
      "  4.33759466e-02 -6.25066876e-01 -2.45247349e-01 -5.06825626e-01\n",
      "  9.33616579e-01 -1.02782324e-01 -6.25997484e-02 -9.72736120e-01\n",
      "  1.51295209e+00 -1.23486318e-01 -2.32186317e-01 -2.07223311e-01\n",
      " -2.90647894e-01 -5.48148513e-01 -4.69092488e-01  1.25078750e+00\n",
      "  0.00000000e+00  4.18695748e-01 -4.27240670e-01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.57501519e-01  8.95373225e-01  0.00000000e+00\n",
      "  8.24725926e-01  1.04969025e+00 -1.74463734e-01 -3.20278227e-01\n",
      " -1.68957859e-01 -2.75275648e-01  6.46683395e-01 -6.68700179e-03\n",
      " -1.56640232e+00 -9.45706107e-03 -1.23875946e-01 -3.10081691e-01\n",
      " -1.36755537e-02  3.35950494e+00 -6.21638410e-02 -4.03235666e-03\n",
      " -6.22954965e-02 -2.01616623e-03 -5.82535900e-02 -5.44045791e-02\n",
      " -3.46494950e-02 -1.00605257e-01 -1.57486796e-02 -9.05798972e-02\n",
      " -2.47003697e-02 -2.24566907e-02 -1.79229174e-02 -7.58224800e-02\n",
      " -6.22663721e-02 -1.66868418e-01 -2.91050702e-01  1.20146859e+00\n",
      "  5.48842587e-02]\n",
      "recon_vec :  [[ 0.22759381  1.8697002   1.1237665   1.0855561  -2.2945795  -1.4173796\n",
      "  -0.7850095  -0.87732106 -1.3695279  -1.47057     1.1104848   0.18532689\n",
      "  -0.23000668  3.9770231   0.74294096 -0.2434959   0.47582504 -0.9099771\n",
      "   1.5755965   2.0467093  -2.7538853   0.39273053  1.3795472  -0.06885573\n",
      "   0.8997668   1.6130749  -2.1511743  -1.0317093   1.2700661   1.9377509\n",
      "  -1.6173967  -0.5123686   0.7943571  -2.4045255  -0.02201633  1.7730261\n",
      "   0.68445396 -1.0087447  -0.10703246  0.517029    1.3764027  -1.2029481\n",
      "  -1.7070446   0.42896587 -0.30687726  0.1165188  -1.5048856   1.9114677\n",
      "   2.2950048   1.2837614   1.8247176  -1.5914508  -2.474552   -1.9429592\n",
      "  -0.29083624  0.16708055 -0.63810104  1.8271568  -0.40978283  0.86177653\n",
      "   2.180374   -1.468082    0.83312243  0.82070684  0.69585353 -0.6701933\n",
      "  -0.2570079  -0.78182     0.36314234  1.4291052   0.42034847  0.3023181\n",
      "   0.98265535 -0.80912393 -0.635771   -0.37635568 -0.18620811  1.9938353\n",
      "   2.1089592  -1.0077653   0.8208669   0.35079017 -2.1334686   0.35461238\n",
      "  -0.6887019  -2.2585633   0.7259335  -0.66950697 -0.08563507 -1.5172067\n",
      "   1.1365695   0.6917431   0.55812263  2.824042    1.3111533  -0.215861\n",
      "  -1.896778   -0.71099037  1.6282529   1.2614406   0.5837809   1.4234015\n",
      "   0.8139911   0.7951758  -0.01828215  0.5155545   3.513725   -0.9847342\n",
      "   0.15067196 -0.5018723   0.25588578  0.5899282  -1.1832091   0.46927536\n",
      "  -0.31199455  1.7330782   1.8877288  -0.8316113   1.9038234  -1.774127\n",
      "  -1.0310504 ]]\n"
     ]
    }
   ],
   "source": [
    "vec = X_test_np[0]\n",
    "z = embedder(torch.tensor(vec, device=DEVICE)).cpu().numpy()\n",
    "p = torch.randn(1, input_dim, device=DEVICE, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([p], lr=1e-2)\n",
    "loss_fn = nn.MSELoss()\n",
    "z_target = torch.tensor(z, device=DEVICE).unsqueeze(0)\n",
    "for _ in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    z_p = embedder(p)\n",
    "    loss = loss_fn(z_p, z_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "p_recon = p.detach().cpu().numpy()\n",
    "print(\"og_vec : \", vec)\n",
    "print(\"recon_vec : \", p_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5171a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1292255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean((vec - p_recon)**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e17823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(vec, p_recon, s=5, alpha=0.6)\n",
    "plt.xlabel(\"Original\")\n",
    "plt.ylabel(\"Reconstructed\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f\"plots/recons.png\",\n",
    "    dpi=1000,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f84686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOUR EMBEDDING\n",
      "AUC: 0.7443782447274898\n",
      "Centroid: 1.0697653\n",
      "Recon MSE: 0.7874517440795898\n",
      "\n",
      "AUTOENCODER BASELINE\n",
      "AUC: 0.7178601799137526\n",
      "Centroid: 0.76531863\n",
      "Recon MSE: 0.35202455520629883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "def linear_probe_auc(Z, y):\n",
    "    clf = LogisticRegression(max_iter=3000)\n",
    "    clf.fit(Z, y)\n",
    "    return roc_auc_score(y, clf.predict_proba(Z)[:, 1])\n",
    "def centroid_distance(Z, y):\n",
    "    fraud = Z[y == 1]\n",
    "    legit = Z[y == 0]\n",
    "    if len(fraud) == 0 or len(legit) == 0:\n",
    "        return 0.0\n",
    "    return np.linalg.norm(fraud.mean(0) - legit.mean(0))\n",
    "# ============================================================\n",
    "# FINAL EMBEDDING COMPARISON (CORRECT & FAIR)\n",
    "# ============================================================\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "# -------------------------\n",
    "# Helper metrics\n",
    "# -------------------------\n",
    "def linear_probe_auc(Z, y):\n",
    "    clf = LogisticRegression(max_iter=3000)\n",
    "    clf.fit(Z, y)\n",
    "    return roc_auc_score(y, clf.predict_proba(Z)[:, 1])\n",
    "def centroid_distance(Z, y):\n",
    "    f = Z[y == 1]\n",
    "    l = Z[y == 0]\n",
    "    return np.linalg.norm(f.mean(0) - l.mean(0))\n",
    "# -------------------------\n",
    "# Helper plots\n",
    "# -------------------------\n",
    "def scatter_plot(Z2, y, name):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.scatter(Z2[:,0], Z2[:,1], c=y, s=6, cmap=\"coolwarm\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{name}.png\", dpi=150)\n",
    "    plt.close()\n",
    "# ============================================================\n",
    "# 1ï¸âƒ£ YOUR EMBEDDING (with post-hoc decoder)\n",
    "# ============================================================\n",
    "Z_yours = get_z_features(embedder, X_test_np)\n",
    "print(\"\\nYOUR EMBEDDING\")\n",
    "print(\"AUC:\", linear_probe_auc(Z_yours, y_test))\n",
    "print(\"Centroid:\", centroid_distance(Z_yours, y_test))\n",
    "# ---- Train decoder ONLY for your embedding\n",
    "# task_decoder = Decoder(Z_DIM, D_HIDDEN, input_dim).to(DEVICE)\n",
    "task_decoder = StrongDecoder(\n",
    "z_dim=Z_DIM,\n",
    "hidden_dims=[Z_DIM, (Z_DIM + X_test_np.shape[1])//2, X_test_np.shape[1]],\n",
    "out_dim=input_dim\n",
    ").to(DEVICE)\n",
    "for p in embedder.parameters(): p.requires_grad = False\n",
    "opt = optim.Adam(task_decoder.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "X_train_t = torch.tensor(X_train_np, device=DEVICE)\n",
    "for _ in range(5):\n",
    "    for i in range(0, len(X_train_t), 2048):\n",
    "        xb = X_train_t[i:i+2048]\n",
    "        with torch.no_grad():\n",
    "            z = embedder(xb)\n",
    "        loss = loss_fn(task_decoder(z), xb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "with torch.no_grad():\n",
    "    X_hat = task_decoder(torch.tensor(Z_yours, device=DEVICE)).cpu().numpy()\n",
    "print(\"Recon MSE:\", mean_squared_error(X_test_np, X_hat))\n",
    "# PCA projection plot\n",
    "scatter_plot(PCA(2).fit_transform(Z_yours), y_test, \"yours_pca\")\n",
    "# Reconstruction scatter\n",
    "f = np.random.randint(0, X_test_np.shape[1])\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(X_test_np[:,f], X_hat[:,f], s=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/yours_recon.png\", dpi=150)\n",
    "plt.close()\n",
    "# ============================================================\n",
    "# 3ï¸âƒ£ AUTOENCODER BASELINE (own encoder + own decoder)\n",
    "# ============================================================\n",
    "ae_embedder = Embedder(input_dim, D_HIDDEN, Z_DIM).to(DEVICE)\n",
    "ae_decoder  = Decoder(Z_DIM, D_HIDDEN, input_dim).to(DEVICE)\n",
    "opt = optim.Adam(list(ae_embedder.parameters()) + list(ae_decoder.parameters()), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "X_train_t = torch.tensor(X_train_np, device=DEVICE)\n",
    "for _ in range(5):\n",
    "    for i in range(0, len(X_train_t), 2048):\n",
    "        xb = X_train_t[i:i+2048]\n",
    "        z = ae_embedder(xb)\n",
    "        loss = loss_fn(ae_decoder(z), xb)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "Z_ae = ae_embedder(torch.tensor(X_test_np, device=DEVICE)).detach().cpu().numpy()\n",
    "X_hat_ae = ae_decoder(torch.tensor(Z_ae, device=DEVICE)).detach().cpu().numpy()\n",
    "print(\"\\nAUTOENCODER BASELINE\")\n",
    "print(\"AUC:\", linear_probe_auc(Z_ae, y_test))\n",
    "print(\"Centroid:\", centroid_distance(Z_ae, y_test))\n",
    "print(\"Recon MSE:\", mean_squared_error(X_test_np, X_hat_ae))\n",
    "scatter_plot(PCA(2).fit_transform(Z_ae), y_test, \"ae_pca\")\n",
    "f = np.random.randint(0, X_test_np.shape[1])\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(X_test_np[:,f], X_hat_ae[:,f], s=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/ae_recon.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa14433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrongerDecoder(nn.Module):\n",
    "    def __init__(self, z_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "\n",
    "def xgb_auc(Z_train, Z_test, y_train, y_test):\n",
    "    dtrain = xgb.DMatrix(Z_train, label=y_train)\n",
    "    dtest  = xgb.DMatrix(Z_test, label=y_test)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"max_depth\": 5,\n",
    "        \"eta\": 0.05,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"nthread\": 8\n",
    "    }\n",
    "\n",
    "    model = xgb.train(params, dtrain, num_boost_round=300)\n",
    "    preds = model.predict(dtest)\n",
    "    return roc_auc_score(y_test, preds)\n",
    "\n",
    "\n",
    "def recon_eval_fast(Z_train, Z_test, X_train, X_test):\n",
    "    # closed-form linear regression\n",
    "    W, _, _, _ = np.linalg.lstsq(Z_train, X_train, rcond=None)\n",
    "    X_hat = Z_test @ W\n",
    "\n",
    "    errs = ((X_hat - X_test) ** 2).mean(axis=1)\n",
    "\n",
    "    plt.hist(errs, bins=100)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Linear Reconstruction MSE\")\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"mse_mean\": errs.mean(),\n",
    "        \"mse_p50\": np.percentile(errs, 50),\n",
    "        \"mse_p90\": np.percentile(errs, 90),\n",
    "    }\n",
    "\n",
    "def evaluate_embedding(name, Z_train, Z_test):\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "\n",
    "    auc = xgb_auc(Z_train, Z_test, y_train, y_test)\n",
    "    print(\"XGB AUC:\", round(auc, 4))\n",
    "\n",
    "    out = {\"auc\": auc}\n",
    "\n",
    "    if Z_train.shape[1] >= 2:\n",
    "        recon = recon_eval_fast(\n",
    "            Z_train, Z_test,\n",
    "            X_train_np, X_test_np\n",
    "        )\n",
    "        print(\n",
    "            \"Recon (linear) MSE:\",\n",
    "            \"mean\", round(recon[\"mse_mean\"], 4),\n",
    "            \"| p50\", round(recon[\"mse_p50\"], 4),\n",
    "            \"| p90\", round(recon[\"mse_p90\"], 4),\n",
    "        )\n",
    "        out.update(recon)\n",
    "    else:\n",
    "        print(\"Recon skipped\")\n",
    "\n",
    "    return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
